{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_120387/1264752695.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BirdsDataset(Dataset):\n",
    "    initial_path = \"./100-birds/\"\n",
    "    transform = T.Resize((190, 190))\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_url = self.x[idx]\n",
    "        image = read_image(f\"{self.initial_path}{file_url}\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        image = image.type(torch.float32)\n",
    "        \n",
    "        return image/255, int(self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BirdModel, self).__init__()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, (11,11), stride=4),\n",
    "            nn.MaxPool2d((3,3)),\n",
    "            nn.Conv2d(96, 256, (3,3), padding=2),\n",
    "            nn.MaxPool2d((3,3), stride=2),\n",
    "            nn.Conv2d(256, 256, (3,3), padding=2),\n",
    "            nn.MaxPool2d((3,3), stride=2),\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(4096, 3000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3000, 600),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(600, 525),\n",
    "            \n",
    "\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 6.259929  [    0/84635]\n",
      "loss: 6.183586  [ 5000/84635]\n",
      "loss: 5.960428  [10000/84635]\n",
      "loss: 5.806148  [15000/84635]\n",
      "loss: 5.402849  [20000/84635]\n",
      "loss: 4.779073  [25000/84635]\n",
      "loss: 4.855789  [30000/84635]\n",
      "loss: 4.624241  [35000/84635]\n",
      "loss: 4.327066  [40000/84635]\n",
      "loss: 4.409547  [45000/84635]\n",
      "loss: 4.556392  [50000/84635]\n",
      "loss: 4.057748  [55000/84635]\n",
      "loss: 3.919068  [60000/84635]\n",
      "loss: 3.748756  [65000/84635]\n",
      "loss: 3.187983  [70000/84635]\n",
      "loss: 3.758808  [75000/84635]\n",
      "loss: 3.430858  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 2.588059 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.546728  [    0/84635]\n",
      "loss: 3.004635  [ 5000/84635]\n",
      "loss: 2.576966  [10000/84635]\n",
      "loss: 2.478292  [15000/84635]\n",
      "loss: 2.959817  [20000/84635]\n",
      "loss: 2.661288  [25000/84635]\n",
      "loss: 2.053031  [30000/84635]\n",
      "loss: 3.186003  [35000/84635]\n",
      "loss: 2.205069  [40000/84635]\n",
      "loss: 2.475085  [45000/84635]\n",
      "loss: 2.427556  [50000/84635]\n",
      "loss: 1.660644  [55000/84635]\n",
      "loss: 2.464640  [60000/84635]\n",
      "loss: 2.120577  [65000/84635]\n",
      "loss: 1.730385  [70000/84635]\n",
      "loss: 1.583346  [75000/84635]\n",
      "loss: 2.298265  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.627906 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.610471  [    0/84635]\n",
      "loss: 1.367142  [ 5000/84635]\n",
      "loss: 1.858891  [10000/84635]\n",
      "loss: 1.514625  [15000/84635]\n",
      "loss: 2.495741  [20000/84635]\n",
      "loss: 1.793141  [25000/84635]\n",
      "loss: 1.957715  [30000/84635]\n",
      "loss: 1.823812  [35000/84635]\n",
      "loss: 1.650981  [40000/84635]\n",
      "loss: 1.928457  [45000/84635]\n",
      "loss: 1.783703  [50000/84635]\n",
      "loss: 1.225275  [55000/84635]\n",
      "loss: 1.698031  [60000/84635]\n",
      "loss: 1.316576  [65000/84635]\n",
      "loss: 1.198372  [70000/84635]\n",
      "loss: 1.652246  [75000/84635]\n",
      "loss: 1.182108  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.282422 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.107753  [    0/84635]\n",
      "loss: 0.745039  [ 5000/84635]\n",
      "loss: 1.003864  [10000/84635]\n",
      "loss: 0.786485  [15000/84635]\n",
      "loss: 0.877254  [20000/84635]\n",
      "loss: 1.325233  [25000/84635]\n",
      "loss: 0.861601  [30000/84635]\n",
      "loss: 1.059539  [35000/84635]\n",
      "loss: 0.571365  [40000/84635]\n",
      "loss: 0.840605  [45000/84635]\n",
      "loss: 1.396291  [50000/84635]\n",
      "loss: 0.825422  [55000/84635]\n",
      "loss: 1.014438  [60000/84635]\n",
      "loss: 1.298880  [65000/84635]\n",
      "loss: 0.816452  [70000/84635]\n",
      "loss: 0.831573  [75000/84635]\n",
      "loss: 1.081797  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 1.195962 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.643546  [    0/84635]\n",
      "loss: 0.528353  [ 5000/84635]\n",
      "loss: 0.513427  [10000/84635]\n",
      "loss: 0.589693  [15000/84635]\n",
      "loss: 0.561505  [20000/84635]\n",
      "loss: 0.368302  [25000/84635]\n",
      "loss: 0.632236  [30000/84635]\n",
      "loss: 0.779825  [35000/84635]\n",
      "loss: 0.543124  [40000/84635]\n",
      "loss: 0.671078  [45000/84635]\n",
      "loss: 0.267688  [50000/84635]\n",
      "loss: 0.671849  [55000/84635]\n",
      "loss: 0.411631  [60000/84635]\n",
      "loss: 0.483667  [65000/84635]\n",
      "loss: 0.848257  [70000/84635]\n",
      "loss: 0.806659  [75000/84635]\n",
      "loss: 0.831910  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 1.234763 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.344418  [    0/84635]\n",
      "loss: 0.392508  [ 5000/84635]\n",
      "loss: 0.227324  [10000/84635]\n",
      "loss: 0.490006  [15000/84635]\n",
      "loss: 0.234737  [20000/84635]\n",
      "loss: 0.253378  [25000/84635]\n",
      "loss: 0.228495  [30000/84635]\n",
      "loss: 0.463950  [35000/84635]\n",
      "loss: 0.414937  [40000/84635]\n",
      "loss: 0.450067  [45000/84635]\n",
      "loss: 0.738575  [50000/84635]\n",
      "loss: 0.290130  [55000/84635]\n",
      "loss: 0.371645  [60000/84635]\n",
      "loss: 0.543249  [65000/84635]\n",
      "loss: 0.241708  [70000/84635]\n",
      "loss: 0.715505  [75000/84635]\n",
      "loss: 0.237234  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.372197 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.432313  [    0/84635]\n",
      "loss: 0.299462  [ 5000/84635]\n",
      "loss: 0.300020  [10000/84635]\n",
      "loss: 0.123954  [15000/84635]\n",
      "loss: 0.179434  [20000/84635]\n",
      "loss: 0.146016  [25000/84635]\n",
      "loss: 0.329566  [30000/84635]\n",
      "loss: 0.402704  [35000/84635]\n",
      "loss: 0.300263  [40000/84635]\n",
      "loss: 0.386345  [45000/84635]\n",
      "loss: 0.358317  [50000/84635]\n",
      "loss: 0.305212  [55000/84635]\n",
      "loss: 0.528049  [60000/84635]\n",
      "loss: 0.761413  [65000/84635]\n",
      "loss: 0.587317  [70000/84635]\n",
      "loss: 0.123917  [75000/84635]\n",
      "loss: 0.477736  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.485295 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.180109  [    0/84635]\n",
      "loss: 0.246448  [ 5000/84635]\n",
      "loss: 0.135242  [10000/84635]\n",
      "loss: 0.168962  [15000/84635]\n",
      "loss: 0.208414  [20000/84635]\n",
      "loss: 0.376079  [25000/84635]\n",
      "loss: 0.292336  [30000/84635]\n",
      "loss: 0.201176  [35000/84635]\n",
      "loss: 0.180685  [40000/84635]\n",
      "loss: 0.228842  [45000/84635]\n",
      "loss: 0.255818  [50000/84635]\n",
      "loss: 0.569137  [55000/84635]\n",
      "loss: 0.204105  [60000/84635]\n",
      "loss: 0.390825  [65000/84635]\n",
      "loss: 0.279839  [70000/84635]\n",
      "loss: 0.283234  [75000/84635]\n",
      "loss: 0.566350  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 1.593424 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.100604  [    0/84635]\n",
      "loss: 0.092069  [ 5000/84635]\n",
      "loss: 0.055816  [10000/84635]\n",
      "loss: 0.434720  [15000/84635]\n",
      "loss: 0.180604  [20000/84635]\n",
      "loss: 0.266480  [25000/84635]\n",
      "loss: 0.187367  [30000/84635]\n",
      "loss: 0.263610  [35000/84635]\n",
      "loss: 0.339128  [40000/84635]\n",
      "loss: 0.153346  [45000/84635]\n",
      "loss: 0.060342  [50000/84635]\n",
      "loss: 0.668341  [55000/84635]\n",
      "loss: 0.438530  [60000/84635]\n",
      "loss: 0.348755  [65000/84635]\n",
      "loss: 0.207118  [70000/84635]\n",
      "loss: 0.266776  [75000/84635]\n",
      "loss: 0.546858  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 1.627802 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.211291  [    0/84635]\n",
      "loss: 0.141992  [ 5000/84635]\n",
      "loss: 0.111579  [10000/84635]\n",
      "loss: 0.153010  [15000/84635]\n",
      "loss: 0.334027  [20000/84635]\n",
      "loss: 0.258654  [25000/84635]\n",
      "loss: 0.152846  [30000/84635]\n",
      "loss: 0.109350  [35000/84635]\n",
      "loss: 0.365343  [40000/84635]\n",
      "loss: 0.416515  [45000/84635]\n",
      "loss: 0.510031  [50000/84635]\n",
      "loss: 0.172006  [55000/84635]\n",
      "loss: 0.064894  [60000/84635]\n",
      "loss: 0.311122  [65000/84635]\n",
      "loss: 0.160969  [70000/84635]\n",
      "loss: 0.198194  [75000/84635]\n",
      "loss: 0.160753  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 1.912160 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.264542  [    0/84635]\n",
      "loss: 0.187994  [ 5000/84635]\n",
      "loss: 0.288791  [10000/84635]\n",
      "loss: 0.063813  [15000/84635]\n",
      "loss: 0.320278  [20000/84635]\n",
      "loss: 0.275155  [25000/84635]\n",
      "loss: 0.154417  [30000/84635]\n",
      "loss: 0.205283  [35000/84635]\n",
      "loss: 0.407485  [40000/84635]\n",
      "loss: 0.393450  [45000/84635]\n",
      "loss: 0.298169  [50000/84635]\n",
      "loss: 0.076852  [55000/84635]\n",
      "loss: 0.102473  [60000/84635]\n",
      "loss: 0.419590  [65000/84635]\n",
      "loss: 0.064690  [70000/84635]\n",
      "loss: 0.103262  [75000/84635]\n",
      "loss: 0.294651  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.800815 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.218830  [    0/84635]\n",
      "loss: 0.054727  [ 5000/84635]\n",
      "loss: 0.090946  [10000/84635]\n",
      "loss: 0.107236  [15000/84635]\n",
      "loss: 0.133110  [20000/84635]\n",
      "loss: 0.038595  [25000/84635]\n",
      "loss: 0.273420  [30000/84635]\n",
      "loss: 0.301691  [35000/84635]\n",
      "loss: 0.089858  [40000/84635]\n",
      "loss: 0.492504  [45000/84635]\n",
      "loss: 0.034434  [50000/84635]\n",
      "loss: 0.156938  [55000/84635]\n",
      "loss: 0.045263  [60000/84635]\n",
      "loss: 0.336649  [65000/84635]\n",
      "loss: 0.491095  [70000/84635]\n",
      "loss: 0.110732  [75000/84635]\n",
      "loss: 0.105305  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 1.940534 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.130971  [    0/84635]\n",
      "loss: 0.155131  [ 5000/84635]\n",
      "loss: 0.160508  [10000/84635]\n",
      "loss: 0.352729  [15000/84635]\n",
      "loss: 0.069609  [20000/84635]\n",
      "loss: 0.096854  [25000/84635]\n",
      "loss: 0.023042  [30000/84635]\n",
      "loss: 0.206513  [35000/84635]\n",
      "loss: 0.112948  [40000/84635]\n",
      "loss: 0.118527  [45000/84635]\n",
      "loss: 0.073793  [50000/84635]\n",
      "loss: 0.202789  [55000/84635]\n",
      "loss: 0.318249  [60000/84635]\n",
      "loss: 0.072876  [65000/84635]\n",
      "loss: 0.244542  [70000/84635]\n",
      "loss: 0.153336  [75000/84635]\n",
      "loss: 0.202019  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 1.998650 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.085235  [    0/84635]\n",
      "loss: 0.088757  [ 5000/84635]\n",
      "loss: 0.205291  [10000/84635]\n",
      "loss: 0.724776  [15000/84635]\n",
      "loss: 0.215222  [20000/84635]\n",
      "loss: 0.129857  [25000/84635]\n",
      "loss: 0.408425  [30000/84635]\n",
      "loss: 0.025603  [35000/84635]\n",
      "loss: 0.132576  [40000/84635]\n",
      "loss: 0.048468  [45000/84635]\n",
      "loss: 0.061875  [50000/84635]\n",
      "loss: 0.050684  [55000/84635]\n",
      "loss: 0.033476  [60000/84635]\n",
      "loss: 0.120414  [65000/84635]\n",
      "loss: 0.083015  [70000/84635]\n",
      "loss: 0.193970  [75000/84635]\n",
      "loss: 0.177074  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 2.106865 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.070694  [    0/84635]\n",
      "loss: 0.171866  [ 5000/84635]\n",
      "loss: 0.038328  [10000/84635]\n",
      "loss: 0.075780  [15000/84635]\n",
      "loss: 0.163039  [20000/84635]\n",
      "loss: 0.243591  [25000/84635]\n",
      "loss: 0.068576  [30000/84635]\n",
      "loss: 0.002170  [35000/84635]\n",
      "loss: 0.117028  [40000/84635]\n",
      "loss: 0.110185  [45000/84635]\n",
      "loss: 0.363091  [50000/84635]\n",
      "loss: 0.157328  [55000/84635]\n",
      "loss: 0.368170  [60000/84635]\n",
      "loss: 0.114397  [65000/84635]\n",
      "loss: 0.128859  [70000/84635]\n",
      "loss: 0.512104  [75000/84635]\n",
      "loss: 0.023286  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 2.142130 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.034996  [    0/84635]\n",
      "loss: 0.179399  [ 5000/84635]\n",
      "loss: 0.007715  [10000/84635]\n",
      "loss: 0.106379  [15000/84635]\n",
      "loss: 0.114350  [20000/84635]\n",
      "loss: 0.230608  [25000/84635]\n",
      "loss: 0.279526  [30000/84635]\n",
      "loss: 0.177066  [35000/84635]\n",
      "loss: 0.227974  [40000/84635]\n",
      "loss: 0.331861  [45000/84635]\n",
      "loss: 0.059008  [50000/84635]\n",
      "loss: 0.200288  [55000/84635]\n",
      "loss: 0.306225  [60000/84635]\n",
      "loss: 0.239677  [65000/84635]\n",
      "loss: 0.107145  [70000/84635]\n",
      "loss: 0.335412  [75000/84635]\n",
      "loss: 0.707513  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 2.430255 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.068096  [    0/84635]\n",
      "loss: 0.301943  [ 5000/84635]\n",
      "loss: 0.053572  [10000/84635]\n",
      "loss: 0.003585  [15000/84635]\n",
      "loss: 0.127229  [20000/84635]\n",
      "loss: 0.049874  [25000/84635]\n",
      "loss: 0.306628  [30000/84635]\n",
      "loss: 0.142271  [35000/84635]\n",
      "loss: 0.014934  [40000/84635]\n",
      "loss: 0.373756  [45000/84635]\n",
      "loss: 0.071564  [50000/84635]\n",
      "loss: 0.038539  [55000/84635]\n",
      "loss: 0.278037  [60000/84635]\n",
      "loss: 0.155808  [65000/84635]\n",
      "loss: 0.431182  [70000/84635]\n",
      "loss: 0.185918  [75000/84635]\n",
      "loss: 0.125838  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 2.052141 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.011345  [    0/84635]\n",
      "loss: 0.167928  [ 5000/84635]\n",
      "loss: 0.018701  [10000/84635]\n",
      "loss: 0.004709  [15000/84635]\n",
      "loss: 0.299272  [20000/84635]\n",
      "loss: 0.054238  [25000/84635]\n",
      "loss: 0.154023  [30000/84635]\n",
      "loss: 0.025808  [35000/84635]\n",
      "loss: 0.079235  [40000/84635]\n",
      "loss: 0.297628  [45000/84635]\n",
      "loss: 0.061425  [50000/84635]\n",
      "loss: 0.522412  [55000/84635]\n",
      "loss: 0.310742  [60000/84635]\n",
      "loss: 0.253337  [65000/84635]\n",
      "loss: 0.162489  [70000/84635]\n",
      "loss: 0.498857  [75000/84635]\n",
      "loss: 0.139682  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 2.392120 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.272500  [    0/84635]\n",
      "loss: 0.114240  [ 5000/84635]\n",
      "loss: 0.042519  [10000/84635]\n",
      "loss: 0.059384  [15000/84635]\n",
      "loss: 0.356805  [20000/84635]\n",
      "loss: 0.119517  [25000/84635]\n",
      "loss: 0.233138  [30000/84635]\n",
      "loss: 0.189484  [35000/84635]\n",
      "loss: 0.124702  [40000/84635]\n",
      "loss: 0.208440  [45000/84635]\n",
      "loss: 0.383906  [50000/84635]\n",
      "loss: 0.234362  [55000/84635]\n",
      "loss: 0.311392  [60000/84635]\n",
      "loss: 0.009108  [65000/84635]\n",
      "loss: 0.108518  [70000/84635]\n",
      "loss: 0.043771  [75000/84635]\n",
      "loss: 0.245757  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 2.503271 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.283283  [    0/84635]\n",
      "loss: 0.030050  [ 5000/84635]\n",
      "loss: 0.286801  [10000/84635]\n",
      "loss: 0.088885  [15000/84635]\n",
      "loss: 0.403268  [20000/84635]\n",
      "loss: 0.117064  [25000/84635]\n",
      "loss: 0.150228  [30000/84635]\n",
      "loss: 0.087079  [35000/84635]\n",
      "loss: 0.191550  [40000/84635]\n",
      "loss: 0.051426  [45000/84635]\n",
      "loss: 0.046238  [50000/84635]\n",
      "loss: 0.019555  [55000/84635]\n",
      "loss: 0.474389  [60000/84635]\n",
      "loss: 0.291948  [65000/84635]\n",
      "loss: 0.217372  [70000/84635]\n",
      "loss: 0.284684  [75000/84635]\n",
      "loss: 0.120033  [80000/84635]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 2.544797 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  train_data = pd.read_csv('./100-birds/birds_train.csv', usecols=['filepaths', 'class id'])\n",
    "  test_data = pd.read_csv('./100-birds/birds_test.csv', usecols=['filepaths','class id'])\n",
    "\n",
    "  batch_size = 50\n",
    "  epochs = 20\n",
    "  learning_rate = 0.0003\n",
    "\n",
    "  loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "  model = BirdModel().to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  \n",
    "  train_dataset = BirdsDataset(train_data['filepaths'].values, train_data['class id'].values)\n",
    "  test_dataset = BirdsDataset(test_data['filepaths'].values, test_data['class id'].values)\n",
    "\n",
    "\n",
    "\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
